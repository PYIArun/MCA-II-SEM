{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "887c4054-c828-4ccd-9ce0-1c885f5da238",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  citations    size inLibrary       price editions\n",
      "0      some   small        no  affordable     many\n",
      "1      many     big        no   expensive      one\n",
      "2      some     big    always   expensive      few\n",
      "3      many  medium        no   expensive     many\n",
      "4      many   small        no  affordable     many\n",
      "\n",
      "0     no\n",
      "1    yes\n",
      "2     no\n",
      "3    yes\n",
      "4    yes\n",
      "Name: buy, dtype: object\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "X = pd.read_csv('dataforCE.csv')\n",
    "y = X['buy']\n",
    "X = X.drop('buy', axis=1)\n",
    "print(X)\n",
    "print()\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d014dc0f-6e0e-45e9-ab3a-dcc6df5d6cc5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final Specific Boundary:  [['many', '?', 'no', '?', '?']]\n",
      "Final General Boundary:  [['many', '?', '?', '?', '?']]\n"
     ]
    }
   ],
   "source": [
    "def consistent(h, d):\n",
    "    # h is hypothesis needs to be checked consistent with the other 'd' hypothesis/training example    \n",
    "    for i in range(len(h)):\n",
    "        if h[i] == '?':\n",
    "            continue    \n",
    "        if h[i] != d[i]:\n",
    "            return False\n",
    "    return True\n",
    "            \n",
    "def generalizeHypothesis(inconsistentHypothesis, d):\n",
    "    general_hypothesis = inconsistentHypothesis.copy()\n",
    "    if all(x is None for x in general_hypothesis):\n",
    "        general_hypothesis.clear()\n",
    "        general_hypothesis = d.copy()\n",
    "    else:\n",
    "        for i in range(len(general_hypothesis)):\n",
    "            if general_hypothesis[i] == '?':\n",
    "                continue    \n",
    "            if general_hypothesis[i] != d[i]:\n",
    "                general_hypothesis[i] = '?'\n",
    "    return general_hypothesis\n",
    "\n",
    "def specializeHypothesis(hypothesis, d, attribute_values):\n",
    "    specializations = []\n",
    "    for i in range(len(hypothesis)):\n",
    "        if hypothesis[i] == '?':  \n",
    "            for val in attribute_values[i]:\n",
    "                if val != d[i]:\n",
    "                    new_hypothesis = hypothesis.copy()\n",
    "                    new_hypothesis[i] = val\n",
    "                    specializations.append(new_hypothesis)\n",
    "        elif hypothesis[i] == d[i]:  \n",
    "            continue\n",
    "    return specializations\n",
    "    \n",
    "# Main Function \n",
    "General_Boundary = [['?', '?', '?', '?', '?']]\n",
    "Specific_Boundary = [[None, None, None, None, None]]\n",
    "\n",
    "attribute_values = [\n",
    "    {\"some\", \"many\"},\n",
    "    {\"small\", \"medium\", \"big\"},\n",
    "    {\"no\", \"always\"},\n",
    "    {\"affordable\", \"expensive\"},\n",
    "    {\"many\", \"one\", \"few\"}\n",
    "]\n",
    "\n",
    "for idx in range(X.shape[0]):\n",
    "    # d is a training example in X's dataframe.\n",
    "    d = X.iloc[idx].tolist()\n",
    "\n",
    "    # d is a positive example\n",
    "    if y[idx] == 'yes':\n",
    "        # Remove from G any hypothesis inconsistent with d\n",
    "        pop_indices = []\n",
    "        for i in range(len(General_Boundary)):\n",
    "            if not consistent(General_Boundary[i], d):\n",
    "                pop_indices.append(i)\n",
    "        for i in reversed(pop_indices):\n",
    "            General_Boundary.pop(i)\n",
    "        \n",
    "        # For each hypothesis in S that is not consistent with d\n",
    "        pop_indices2 = []\n",
    "        for i in range(len(Specific_Boundary)):\n",
    "            if not consistent(Specific_Boundary[i], d):\n",
    "                pop_indices2.append(i)\n",
    "\n",
    "                # Add to S all minimal generalizations h of s such that (h is consistent with d)\n",
    "                hypothesis = generalizeHypothesis(Specific_Boundary[i], d)\n",
    "                Specific_Boundary.append(hypothesis)\n",
    "\n",
    "        for i in reversed(pop_indices2):\n",
    "            Specific_Boundary.pop(i)\n",
    "\n",
    "    # d is a negative example\n",
    "    else:\n",
    "        # Remove from S any hypothesis inconsistent with d\n",
    "        pop_indices3 = []\n",
    "        for i in range(len(Specific_Boundary)):\n",
    "            if consistent(Specific_Boundary[i], d):\n",
    "                pop_indices3.append(i)\n",
    "        for i in reversed(pop_indices3):\n",
    "            Specific_Boundary.pop(i)\n",
    "\n",
    "        # For each hypothesis in G that is not consistent with d\n",
    "        pop_indices4 = []\n",
    "        new_specializations = []\n",
    "        for i in range(len(General_Boundary)):\n",
    "            if consistent(General_Boundary[i], d):\n",
    "                pop_indices4.append(i)\n",
    "                \n",
    "                hypothesis = specializeHypothesis(General_Boundary[i], d, attribute_values)\n",
    "                new_specializations.extend(hypothesis)\n",
    "\n",
    "        # Remove inconsistent hypotheses from G \n",
    "        for i in reversed(pop_indices4):\n",
    "            General_Boundary.pop(i)\n",
    "\n",
    "        # Add minimal specializations to G\n",
    "        for h in new_specializations:\n",
    "            should_add = True\n",
    "            for s in Specific_Boundary:\n",
    "                if consistent(s, h):\n",
    "                    should_add = False\n",
    "                    break\n",
    "            if should_add:\n",
    "                General_Boundary.append(h)\n",
    "\n",
    "        # Remove from G any hypothesis that is less general than another hypothesis in G\n",
    "        pop_indices5 = []\n",
    "        for i in range(len(General_Boundary)):\n",
    "            for j in range(len(General_Boundary)):\n",
    "                if i != j and consistent(General_Boundary[j], General_Boundary[i]):\n",
    "                    pop_indices5.append(i)\n",
    "        for i in reversed(pop_indices5):\n",
    "            General_Boundary.pop(i)\n",
    "\n",
    "print(\"Final Specific Boundary: \", Specific_Boundary)\n",
    "print(\"Final General Boundary: \", General_Boundary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "52097337-0a98-47f7-803e-c179a06ae182",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generating Version Space\n",
    "from itertools import product\n",
    "def generate_version_space(S, G):\n",
    "    S = [s for s in S]\n",
    "    G = [g for g in G]\n",
    "    # Empty version space\n",
    "    version_space = set()\n",
    "    # For each specific and general boundary hypothesis\n",
    "    for s in S:\n",
    "        for g in G:\n",
    "            # Including all domain values of attributes\n",
    "            attr_domains = []\n",
    "            for i in range(len(s)):\n",
    "                if s[i] == g[i]:\n",
    "                    attr_domains.append(s[i])\n",
    "                elif s[i] == '?':\n",
    "                    attr_domains.append(['?'])\n",
    "                else:\n",
    "                    attr_domains.append([s[i], '?'])\n",
    "            # Extract nested lists and their indices\n",
    "            nested_indices = [i for i, x in enumerate(attr_domains) if isinstance(x, list)]\n",
    "            nested_lists = [attr_domains[i] for i in nested_indices]\n",
    "            # Generate all possible combinations\n",
    "            combinations = list(product(*nested_lists))\n",
    "            for combo in combinations:\n",
    "                temp_list = attr_domains.copy()\n",
    "                for idx, value in zip(nested_indices, combo):\n",
    "                    temp_list[idx] = value\n",
    "                version_space.add(tuple(temp_list))\n",
    "    return version_space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "080d9346-08b7-4035-8258-f98f2a5cae42",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Version Space:  {('many', '?', '?', '?', '?'), ('many', '?', 'no', '?', '?')}\n"
     ]
    }
   ],
   "source": [
    "Version_Space = generate_version_space(Specific_Boundary,General_Boundary)\n",
    "print(\"Version Space: \", Version_Space)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
